{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059589e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "from firebase import firebase\n",
    "from keras.preprocessing import image\n",
    "firebase= firebase.FirebaseApplication(\"https://finalppt-a818d-default-rtdb.firebaseio.com/\", None)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (50, 50)\n",
    "fontScale = 1\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "from tensorflow import keras\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(static_image_mode=False,\n",
    "                      max_num_hands=1,\n",
    "                      min_detection_confidence=0.5,\n",
    "                      min_tracking_confidence=0.5)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "pTime = 0\n",
    "cTime = 0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    lx=[]\n",
    "    ly=[]\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    #print(results.multi_hand_landmarks)\n",
    "    if results.multi_hand_landmarks:\n",
    "        \n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            for id, lm in enumerate(handLms.landmark):\n",
    "                #print(id,lm)\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x *w), int(lm.y*h)\n",
    "                lx.append(cx)\n",
    "                ly.append(cy)\n",
    "                cv2.circle(img, (cx,cy), 3, (255,0,255), cv2.FILLED)\n",
    "        mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)\n",
    "        #cv2.rectangle(img, (min(lx)-50,min(ly)-50), (max(lx)+50,max(ly)+50), (255, 0, 0), 2)\n",
    "        if ly[8]== min(ly):\n",
    "            gesture= \"isJump\"\n",
    "        elif ly[6]<ly[8] and ly[10]<ly[12] and ly[14]<ly[16] and ly[18]<ly[20]:\n",
    "            gesture= \"isHold\"\n",
    "        elif ly[6]>ly[8] and ly[10]>ly[12] and ly[14]>ly[16] and ly[18]>ly[20]:\n",
    "            gesture= \"isMove\"\n",
    "    else:\n",
    "        gesture= \"isHold\"\n",
    "            \n",
    "    img = cv2.putText(img, gesture , org, font, \n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "    my_file = open(\"intermediate_script.txt\", \"w\")\n",
    "    my_file.write(gesture)\n",
    "    img= cv2.resize(img,(720,720))\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088ecfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
